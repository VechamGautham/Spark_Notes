{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afbb50f",
   "metadata": {},
   "source": [
    "## üìë Table of Contents\n",
    "- [Spark Dataframe Partitions](#spark-dataframe-partitions)\n",
    "-  [Spark Transformation and Dependencies](#spark-transformations--dependencies)\n",
    "    - [Narrow Dependency](#2-narrow-dependency-transformation)\n",
    "    - [Wide Dependency](#3-wide-dependency-transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a45fab",
   "metadata": {},
   "source": [
    "# Spark DataFrame Partitions\n",
    "\n",
    "## 1. Data Stored in Distributed Systems\n",
    "- In real life, files (CSV, JSON, etc.) are stored in **distributed storage** like HDFS or Amazon S3.  \n",
    "- The file is **split into partitions** and spread across nodes.  \n",
    "  - Example: 100 partitions across 10 nodes.  \n",
    "- This splitting makes **parallel reading** possible.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Logical DataFrame\n",
    "- When you call `spark.read.csv(\"file.csv\")`, Spark creates a **logical DataFrame**:\n",
    "  - Stores **metadata**: schema, partition info, and how to read them.\n",
    "  - **No data is loaded yet** (lazy evaluation).  \n",
    "- Think of it like a **recipe**: instructions exist, but the meal (data) isn‚Äôt cooked until you trigger an action.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Role of the Driver (SparkSession)\n",
    "- The driver (your `spark` session) is the **brain**:\n",
    "  - Contacts cluster manager + storage.\n",
    "  - Collects info about partitions.\n",
    "  - Creates the **plan** to process them.\n",
    "- Still, the driver does not load data itself.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Executors (the workers)\n",
    "- Executors are **JVM processes** launched by the cluster manager.  \n",
    "- They do the **real work**:\n",
    "  - Load their assigned partitions into memory.\n",
    "  - Run tasks (filter, join, aggregate, etc.).  \n",
    "- Each executor has multiple **cores**, and each core processes **one partition at a time**.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Answer to the Doubt ‚úÖ\n",
    "- If you have **5 executors** and **5 cores per executor**:  \n",
    "  - Total = `5 √ó 5 = 25 cores`.  \n",
    "- That means **25 partitions can be processed in parallel**.  \n",
    "- ‚ö†Ô∏è Notes:\n",
    "  - If partitions < 25, some cores stay idle.  \n",
    "  - If partitions > 25, Spark processes them in **waves** (25 at a time).  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Data Locality Optimization\n",
    "- Spark tries to assign each partition to an executor **close to where the data is stored**.  \n",
    "- This reduces network traffic and speeds up jobs.  \n",
    "- If not possible, Spark still works, but with some data transfer over the network.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Final Picture\n",
    "A **distributed DataFrame** is created:\n",
    "- Driver manages the plan.  \n",
    "- Executors (with multiple cores) load and process partitions in parallel.  \n",
    "- Together, they form a **scalable system** for big data.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Diagram\n",
    "![Spark DataFrame Partitions](./images/driver_execution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f8642e",
   "metadata": {},
   "source": [
    "# Spark Transformations & Dependencies\n",
    "\n",
    "## 1. What are Transformations?\n",
    "- Spark DataFrames are **immutable**.  \n",
    "- To process data, you don‚Äôt ‚Äúmodify‚Äù a DataFrame. Instead, you apply **transformations**:\n",
    "  - Examples: `select()`, `filter()`, `groupBy()`, `orderBy()`.\n",
    "- Each transformation produces a **new DataFrame** (logically), building a chain of operations.\n",
    "- Together, transformations form a **DAG (Directed Acyclic Graph)** of operations.\n",
    "\n",
    "üìä Example:  \n",
    "![Spark Transformations](./images/transformations.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Narrow Dependency Transformation\n",
    "- A transformation is **narrow** when each partition can be processed **independently**, without needing data from other partitions.\n",
    "- Executors can process partitions locally ‚Üí results are later combined.  \n",
    "- These are usually **map-style operations**.\n",
    "\n",
    "### üîπ Examples of Narrow Dependencies:\n",
    "- `select(\"col1\", \"col2\")` ‚Üí choosing columns.  \n",
    "- `filter(df.col > 10)` / `where(df.col < 40)` ‚Üí row filtering.  \n",
    "- `withColumn(\"newCol\", df.col * 2)` ‚Üí column-level transformation.  \n",
    "- `map()` / `flatMap()` ‚Üí functional transformations.  \n",
    "- `count()` (after shuffle stage is done) ‚Üí counts within a partition.  \n",
    "\n",
    "üìä Visualization:  \n",
    "![Narrow Dependency](./images/narrow_dependency.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Wide Dependency Transformation\n",
    "- A transformation is **wide** when data from **multiple partitions must be shuffled** to produce a correct result.\n",
    "- Spark performs a **shuffle/sort exchange** ‚Üí redistributes data across partitions.  \n",
    "- These are usually **reduce-style operations**.\n",
    "\n",
    "### üîπ Examples of Wide Dependencies:\n",
    "- `groupBy(\"col\").count()` ‚Üí needs all rows of a group together.  \n",
    "- `orderBy(\"col\")` / `sort()` ‚Üí needs global ordering.  \n",
    "- `distinct()` ‚Üí requires shuffling duplicates across partitions.  \n",
    "- `join(df1, df2, \"col\")` ‚Üí rows with the same key must meet.  \n",
    "- `reduceByKey()` / `aggregateByKey()` (in RDDs).  \n",
    "\n",
    "üìä Problem (before shuffle):  \n",
    "![Wide Dependency Problem](./images/wide_dependecy_prob.png)\n",
    "\n",
    "üìä Solution (after shuffle + repartition):  \n",
    "![Wide Dependency Solution](./images/wide_denpendency_sol.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 4. ‚ùì Your Doubt ‚Äî What if a Group is Too Big for One Partition?\n",
    "- Spark‚Äôs default shuffle partition size is **~128 MB** (not KB).  \n",
    "- After `groupBy()`, Spark ensures all rows of the same group key land in the **same partition**.  \n",
    "- But if one group is **larger than 128 MB**, what happens?\n",
    "\n",
    "### ‚úÖ The Answer:\n",
    "1. **Partition size is not a hard cap**  \n",
    "   - Spark can create partitions larger than 128 MB if needed.  \n",
    "   - The big group is stored in one partition, even if it exceeds the ‚Äúideal‚Äù size.\n",
    "\n",
    "2. **Aggregation correctness is preserved**  \n",
    "   - Example: `count()` runs within that partition only.  \n",
    "   - So logically, `count()` is still a **narrow dependency** (independent of other partitions).\n",
    "\n",
    "3. **Performance concerns (data skew)**  \n",
    "   - One executor may get a huge partition ‚Üí slower job.  \n",
    "   - Spark prevents crashes by spilling to disk if memory runs out.\n",
    "\n",
    "4. **Optimizations in practice**  \n",
    "   - Increase shuffle partitions (`spark.sql.shuffle.partitions`).  \n",
    "   - Apply *salting keys* to break very large groups into subgroups.  \n",
    "   - Use Spark‚Äôs **skew join optimization** (Spark 3+).\n",
    "\n",
    "üëâ So: correctness is always maintained, but performance may degrade if data skew is high.\n",
    "\n",
    "---\n",
    "\n",
    "# üìù Summary\n",
    "- **Narrow dependency**: map-style operations ‚Üí `select`, `filter`, `withColumn`, `map`, `count` (post-shuffle).  \n",
    "- **Wide dependency**: reduce-style operations ‚Üí `groupBy`, `orderBy`, `join`, `distinct`, `reduceByKey`.  \n",
    "- **Large group in wide dependency**: Spark allows big partitions ‚Üí results are correct, but skew can slow down jobs."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
