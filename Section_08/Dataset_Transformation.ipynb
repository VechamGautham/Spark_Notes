{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d45c7b",
   "metadata": {},
   "source": [
    "# Table of Contents \n",
    "- [Introduction to Transformations](#introduction-to-transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256c0e5",
   "metadata": {},
   "source": [
    "# Introduction to Transformations\n",
    "\n",
    "![Introduction to Transformations](./images/intro_transformation.png)\n",
    "\n",
    "Transformations in Apache Spark are the **core operations** that allow us to manipulate data.  \n",
    "They take a DataFrame (or table) as input and return a new DataFrame without changing the original one.  \n",
    "\n",
    "Think of it as the \"cooking step\" in data engineering:\n",
    "- **Data Source** → raw ingredients\n",
    "- **Transformations** → chopping, mixing, seasoning\n",
    "- **Data Sink** → final dish, ready to serve\n",
    "\n",
    "## Types of Transformations\n",
    "\n",
    "1. **Combining DataFrames** – merge or stack datasets using `join`, `union`.\n",
    "2. **Aggregating & Summarizing** – use `groupBy`, window functions, or rollups to compute totals, averages, ranks, etc.\n",
    "3. **Applying Built-in Transformations** – filter rows, sort values, sample data, or remove duplicates.\n",
    "4. **Column-level Functions** – use Spark SQL functions (e.g., `upper`, `substring`, `length`) on specific columns.\n",
    "5. **User-Defined Functions (UDFs)** – write custom logic when built-ins are not enough.\n",
    "6. **Referencing Rows/Columns** – select or rename columns, reference values, or create new derived fields.\n",
    "7. **Creating Column Expressions** – build formulas and expressions like `col(\"price\") * 0.9` for discounts.\n",
    "\n",
    "With these, you can handle almost any real-world transformation task in Spark."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
