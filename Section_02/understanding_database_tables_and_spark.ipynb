{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55bbbaf0",
   "metadata": {},
   "source": [
    "# Table of Contents \n",
    "- [Understanding database tables and spark dataframes](#understanding-database-tables-and-spark-dataframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf9e1e7",
   "metadata": {},
   "source": [
    "# Understanding Database Tables and Spark DataFrames\n",
    "\n",
    "---\n",
    "\n",
    "## Database Tables\n",
    "\n",
    "We learned that databases are one of the most popular data processing platforms.  \n",
    "At a high level, they offer **Tables** and **SQL**.\n",
    "\n",
    "- **Table = Schema + Data**\n",
    "- **Schema** is stored in the **metadata store** (data dictionary).\n",
    "- **Data** is stored in underlying files on disk.\n",
    "- Users only see the **logical table**, not the physical files.\n",
    "\n",
    "![Database Table](./images/sql_database.png)\n",
    "\n",
    "---\n",
    "\n",
    "### How SQL Executes\n",
    "\n",
    "1. User submits SQL query to the SQL Engine.  \n",
    "2. SQL Engine consults the **metadata store** (for schema validation).  \n",
    "3. If you use a non-existent column, an **analysis error** is thrown.  \n",
    "4. If query passes schema validation:\n",
    "   - Engine reads data from physical files.\n",
    "   - Processes data.\n",
    "   - Returns results.\n",
    "\n",
    "![SQL Engine Flow](./images/sql_database_1.png)\n",
    "\n",
    "---\n",
    "\n",
    "### Table Layers in a Database\n",
    "\n",
    "- **Storage Layer** → physical files on disk.  \n",
    "- **Metadata Layer** → schema and schema info.  \n",
    "- **Logical Layer** → database table exposed to users.  \n",
    "\n",
    "![Database Table Layers](./images/database_table.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Spark Tables\n",
    "\n",
    "Apache Spark is also a data processing platform.  \n",
    "It provides two ways:\n",
    "- **Spark Tables (SQL-like)**  \n",
    "- **DataFrames (API-based)**  \n",
    "\n",
    "Spark tables are similar to database tables:  \n",
    "- Schema stored in a metadata store.  \n",
    "- Data stored in files (but Spark supports many formats: CSV, JSON, Parquet, Avro, XML, etc.).  \n",
    "- Storage can be distributed (HDFS, S3, ADLS).\n",
    "\n",
    "![Spark Table](./images/spark_database.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Spark DataFrames\n",
    "\n",
    "A **DataFrame** is structurally the same as a table, but:  \n",
    "- Schema is **not in persistent metastore**.  \n",
    "- Instead, it’s stored in a **runtime catalog** (in-memory).  \n",
    "- Exists only during the Spark application.  \n",
    "- Deleted once the Spark job ends.  \n",
    "\n",
    "This allows Spark to support **schema-on-read**:\n",
    "- You define schema at read time.\n",
    "- Spark applies it to the file and builds a temporary DataFrame object.\n",
    "\n",
    "![Spark DataFrame](./images/spark_dataframes.png)\n",
    "\n",
    "---\n",
    "\n",
    "## Spark Table vs Spark DataFrame\n",
    "\n",
    "| Spark Table | Spark DataFrame |\n",
    "|-------------|-----------------|\n",
    "| Schema in **metadata store** (persistent). | Schema in **runtime catalog** (temporary). |\n",
    "| Persistent, visible across applications. | Runtime-only, visible only in current app. |\n",
    "| Predefined schema required when creating table. | Schema-on-read (defined at load time). |\n",
    "| Supports SQL expressions. | Supports APIs, not SQL. |\n",
    "| Convertible → Table ↔ DataFrame. | Convertible → DataFrame ↔ Table. |\n",
    "\n",
    "![Spark Table vs DataFrame](./images/spark_vs_data_frame.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c54025",
   "metadata": {},
   "source": [
    "# Spark DataFrame Methods\n",
    "\n",
    "![DataFrame Methods](./images/dataframe_methods_.png)\n",
    "\n",
    "Spark DataFrame methods are grouped into three categories:\n",
    "\n",
    "1. **Actions**  \n",
    "   - Kick off a Spark Job execution  \n",
    "   - Return results to the Spark driver  \n",
    "\n",
    "   ![Actions & Transformations](./images/actions_and_transformations.png)\n",
    "\n",
    "2. **Transformations**  \n",
    "   - Produce a new transformed DataFrame  \n",
    "   - Do **not** trigger a Spark Job immediately  \n",
    "\n",
    "3. **Functions / Utility Methods**  \n",
    "   - Other DataFrame functions not classified as Actions or Transformations  \n",
    "\n",
    "   ![Functions & Methods](./images/methods.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
